import utils
import google
import pandas as pd
import datetime as dt
from locations import divide_region


TIME_ZONE_OFFSET = -dt.timedelta(hours=7)


def staged_finder(region, term, zoom=15, batch_size=100):
    """
    Stage search approach to getting all items in a region. Will run a query at a
    course zoom to get a set of points that it should be calling. Based on that query
    it will then go through 2 more levels of calls to determine the calls that it 
    should be making
    """
    lat, lng, viewport = google.get_lat_lng(region, viewport=True)
    nw, se = viewport
    center = lat, lng
    run_identifier = {
        'center': utils.to_geojson(center),
        'viewport': {
            'nw': utils.to_geojson(nw),
            'se': utils.to_geojson(se)
        },
        'zoom': zoom
    }
    log_identifier = dict(run_identifier, **{'method': 'stage_finder'})
    has_document = utils.DB_STAGING.find_one(run_identifier)
    if not has_document:
        stage_dict = {'stage': 1}
        coords = [dict(run_identifier, **stage_dict, **{'query_point': utils.to_geojson(query_point)})
                  for query_point in divide_region(center, viewport, zoom)]
        try:
            log_identifier['1st_stage_points'] = len(coords)
            log_identifier['created_at'] = dt.datetime.now(tz=dt.timezone(TIME_ZONE_OFFSET))
            utils.DB_LOG.insert_one(log_identifier)
            utils.DB_STAGING.insert_many(coords, ordered=False)
        except utils.BWE:
            print('Center, viewport, zoom, combo already in database, please check.')
            raise

    stage_caller(run_identifier, term, 1, batch_size, zoom, log_identifier)
    stage_caller(run_identifier, term, 2, batch_size, 18, log_identifier)
    stage_caller(run_identifier, term, 3, batch_size, 18, log_identifier)


def stage_caller(run_identifier, term, stage, batch_size, zoom, log):

    print("Starting Stage: {}".format(stage))
    size = {'size': batch_size}
    query = {
        'processed_terms': {'$nin': [term]},
        'stage': stage,
    }
    # only call on terms that were generated by this search
    stage > 1 and query.update({'generating_term': term})
    query = dict(run_identifier, **query)

    # for stage 3 and above, only querying half the points.
    remaining_queries = None
    if stage >= 3:
        unprocessed = utils.DB_STAGING.count_documents(query)
        num_stage_query = query.copy()
        num_stage_query.pop('processed_terms')
        all_queries = utils.DB_STAGING.count_documents(num_stage_query)
        print("unprocessed", unprocessed, "all_queries", all_queries, term)
        if unprocessed < all_queries / 2:
            print("Already called half of stage {} items".format(stage))
            return
        else:
            remaining_queries = unprocessed - all_queries / 2

    while True:

        remaining_queries and print("{} remaining queries!".format(remaining_queries))

        point_documents = list(utils.DB_STAGING.aggregate([
            {'$match': query},
            {'$sample': size}
        ]))

        if len(point_documents) == 0 or (remaining_queries and remaining_queries <= 0):
            print('Stage {} Completed!'.format(stage))
            return

        queried_ids = [document['_id'] for document in point_documents]
        latlngs = [tuple(reversed(document['query_point']['coordinates']))
                   for document in point_documents]

        nearby_scraper = google.GoogleNearby('STAGE NEARBY SCRAPER')
        urls = [nearby_scraper.build_request(term, lat, lng, zoom)
                for (lat, lng) in latlngs]

        results, new_locations = zip(*nearby_scraper.async_request(
            urls,
            pool_limit=20,
            timeout=10,
            quality_proxy=True,
            res_parser=get_lat_and_response
        ))
        results = [utils.split_name_address(place, as_dict=True)
                   for place in set(utils.flatten(results))]
        next_stage_dict = {'stage': stage + 1, 'generating_term': term}
        new_locations = [dict(run_identifier, **next_stage_dict, **{'query_point': utils.to_geojson(location)})
                         for location in utils.flatten(new_locations)]

        try:
            utils.DB_STAGING_RESULTS.insert_many(results, ordered=False)
            results_inserted = len(results)
        except utils.BWE as bwe:
            results_inserted = bwe.details['nInserted']
        try:
            utils.DB_STAGING.insert_many(new_locations, ordered=False)
            locations_inserted = len(new_locations)
        except utils.BWE as bwe:
            locations_inserted = bwe.details['nInserted']

        utils.DB_STAGING.update_many({'_id': {'$in': queried_ids}}, {'$push': {
            'processed_terms': term
        }})

        print("STAGE: Number of Stage {} Points Queried: {}".format(stage, len(queried_ids)))
        print("STAGE: Number of Stage {} Points Inserted: {}".format(stage + 1, locations_inserted))
        print("STAGE: Number of Results Inserted: {}".format(results_inserted))

        remaining_queries = remaining_queries - len(queried_ids) if remaining_queries else None

        utils.DB_LOG.update_one(log, {
            '$inc': {
                term + '_stage' + str(stage) + '_queried_points': len(queried_ids),
                term + '_' + str(stage + 1) + '_stage_points': locations_inserted,
                term + '_places_inserted': results_inserted
            },
            '$set': {
                term + '_updated_last': dt.datetime.now(tz=dt.timezone(TIME_ZONE_OFFSET))
            }
        })


def get_lat_and_response(response):
    return (google.GoogleNearby.default_parser(response),
            google.GoogleNearby.parse_nearest_latlng(response))


def print_zoom_region(region, zoom):
    lat, lng, viewport = google.get_lat_lng(region, viewport=True)
    nw, se = viewport
    center = lat, lng
    coords = []
    points = divide_region(center, viewport, zoom)
    # Use the following script to simply print out the regions.
    for item in points:
        coords.append({
            'latitude': item[0],
            'longitude': item[1]
        })
    pd.DataFrame(coords).to_csv('datapoints.csv')


def get_locations():

    locations = utils.DB_STAGING.find({
        'zoom': 15,
        '$or': [
            {'stage': 2},
            {'stage': 3}
        ]
    })
    pd.DataFrame([utils.from_geojson(location['query_point'], as_dict=True) for location in locations]).to_csv('new_items.csv')


if __name__ == "__main__":
    # print_zoom_region("Los Angeles", 15)
    for item in ["restaurants", "stores", "auto shop", "cafe", "coffee shop"]:
        staged_finder("Los Angeles", item, batch_size=100)
    # get_locations()
